{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install project dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python==4.6.0.66\n",
    "%pip install mediapipe==0.8.11\n",
    "%pip install numpy==1.22.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries for drawing and face mesh detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_face_mesh = mp.solutions.face_mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the key points for the left eye and right eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_left_eye = [385, 380, 387, 373, 362, 263]\n",
    "p_right_eye = [160, 144, 158, 153, 33, 133]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine key points for both left and right eyes into a single list and display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_eyes = p_left_eye+p_right_eye\n",
    "p_eyes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calculates the Eye Aspect Ratio (EAR) for both the left and right eyes using the provided face landmarks and specific eye landmarks. The result is the average EAR for both eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ear(face, p_right_eye, p_left_eye):\n",
    "  '''Calculates the Eye Aspect Ratio (EAR) of a face'''\n",
    "\n",
    "  try:\n",
    "    # Extracting coordinates of the face landmarks\n",
    "    face = np.array([[coord.x, coord.y] for coord in face])\n",
    "\n",
    "    # Extracting coordinates of the left eye landmarks\n",
    "    face_left = face[p_left_eye, :]\n",
    "\n",
    "    # Extracting coordinates of the right eye landmarks\n",
    "    face_right = face[p_right_eye, :]\n",
    "\n",
    "    # Calculating Eye Aspect Ratio (EAR) for the left eye\n",
    "    ear_left = (np.linalg.norm(face_left[0] - face_left[1]) + np.linalg.norm(face_left[2] - face_left[3])) / (2 * (np.linalg.norm(face_left[4] - face_left[5])))\n",
    "\n",
    "    # Calculating Eye Aspect Ratio (EAR) for the right eye\n",
    "    ear_right = (np.linalg.norm(face_right[0] - face_right[1]) + np.linalg.norm(face_right[2] - face_right[3])) / (2 * (np.linalg.norm(face_right[4] - face_right[5])))\n",
    "    \n",
    "  except:\n",
    "    # Set EAR values to 0.0 in case of an exception\n",
    "    ear_left = 0.0\n",
    "    ear_right = 0.0\n",
    "    \n",
    "  # Calculate the average EAR for both eyes\n",
    "  median_ear = (ear_left + ear_right) / 2\n",
    "  \n",
    "  return median_ear\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the key points for the mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mouth = [82, 87, 13, 14, 312, 317, 78, 308]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function calculates the Mouth Aspect Ratio (MAR) using the provided face landmarks and specific mouth landmarks. The result is the MAR, and if an exception occurs, it sets the value to 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mar(face, p_mouth):\n",
    "  '''Calculates the mouth aspect ratio (MAR) of a face'''\n",
    "  try:\n",
    "    # Extracting coordinates of the face landmarks\n",
    "    face = np.array([[coord.x, coord.y] for coord in face])\n",
    "\n",
    "    # Extracting coordinates of the mouth landmarks\n",
    "    face_mouth = face[p_mouth, :]\n",
    "\n",
    "    # Calculating Mouth Aspect Ratio (MAR)\n",
    "    mar = (np.linalg.norm(face_mouth[0] - face_mouth[1]) + \n",
    "            np.linalg.norm(face_mouth[2] - face_mouth[3]) + \n",
    "            np.linalg.norm(face_mouth[4] - face_mouth[5])) / (2 * (np.linalg.norm(face_mouth[6] - face_mouth[7])))\n",
    "  except:\n",
    "    # Set MAR to 0.0 in case of an exception\n",
    "    mar = 0.0\n",
    "    \n",
    "  return mar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real-time blink detection and sleepiness monitoring system, analyzing facial landmarks to provide feedback on the user's eye and mouth movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set thresholds for Eye Aspect Ratio (EAR) and Mouth Aspect Ratio (MAR)\n",
    "ear_threshold = 0.3\n",
    "mar_threshold = 0.1\n",
    "\n",
    "# Initialize variables for tracking eye status and blink count\n",
    "sleeping = 0\n",
    "blink_count = 0\n",
    "\n",
    "# Initialize time-related variables\n",
    "elapsed_time = 0\n",
    "temporary_count = 0\n",
    "count_list = []\n",
    "\n",
    "# Get the initial time for blink tracking\n",
    "t_blinks = time.time()\n",
    "\n",
    "# Open the camera (assuming camera index 1, you may need to adjust)\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# Set up FaceMesh with confidence thresholds\n",
    "with mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5) as facemesh:\n",
    "  while cap.isOpened():\n",
    "    # Read a frame from the camera\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    # If the frame is empty, skip it\n",
    "    if not success:\n",
    "      print('Ignoring empty camera frame.')\n",
    "      continue\n",
    "\n",
    "    # Get the dimensions of the frame\n",
    "    width, height, _ = frame.shape\n",
    "\n",
    "    # Convert the frame to RGB for FaceMesh processing\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    facemesh_output = facemesh.process(frame)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    try:\n",
    "      # Iterate through detected face landmarks\n",
    "      for face_landmarks in facemesh_output.multi_face_landmarks:\n",
    "        # Draw FaceMesh landmarks on the frame\n",
    "        mp_drawing.draw_landmarks(frame, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,\n",
    "          landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 102, 102), thickness=1, circle_radius=1),\n",
    "          connection_drawing_spec=mp_drawing.DrawingSpec(color=(102, 204, 0), thickness=1, circle_radius=1))\n",
    "\n",
    "        # Extract face landmarks\n",
    "        face = face_landmarks.landmark\n",
    "\n",
    "        # Draw circles on eye and mouth landmarks\n",
    "        for id_coord, coord_xyz in enumerate(face):\n",
    "          if id_coord in p_eyes:\n",
    "            coord_cv = mp_drawing._normalized_to_pixel_coordinates(coord_xyz.x, coord_xyz.y, height, width)\n",
    "            cv2.circle(frame, coord_cv, 2, (255, 0, 0), -1)\n",
    "          if id_coord in p_mouth:\n",
    "            coord_cv = mp_drawing._normalized_to_pixel_coordinates(coord_xyz.x, coord_xyz.y, height, width)\n",
    "            cv2.circle(frame, coord_cv, 2, (255, 0, 0), -1)\n",
    "\n",
    "        # Calculate Eye Aspect Ratio (EAR) and draw information on the frame\n",
    "        ear = calculate_ear(face, p_right_eye, p_left_eye)\n",
    "        cv2.rectangle(frame, (0, 1), (290, 140), (58, 58, 55), -1)\n",
    "        cv2.putText(frame, f\"EAR: {round(ear, 2)}\", (1, 24),\n",
    "          cv2.FONT_HERSHEY_DUPLEX,\n",
    "          0.9, (255, 255, 255), 2)\n",
    "\n",
    "        # Calculate Mouth Aspect Ratio (MAR) and draw information on the frame\n",
    "        mar = calculate_mar(face, p_mouth)\n",
    "        cv2.putText(frame, f\"MAR: {round(mar, 2)} {'Open' if mar >= mar_threshold else 'Closed'}\", (1, 50),\n",
    "          cv2.FONT_HERSHEY_DUPLEX,\n",
    "          0.9, (255, 255, 255), 2)\n",
    "                \n",
    "        # Track blink events based on EAR and MAR\n",
    "        if ear < ear_threshold and mar < mar_threshold:\n",
    "          t_initial = time.time() if sleeping == 0 else t_initial\n",
    "          blink_count = blink_count + 1 if sleeping == 0 else blink_count\n",
    "          sleeping = 1\n",
    "        if (sleeping == 1 and ear >= ear_threshold) or (ear <= ear_threshold and mar >= mar_threshold):\n",
    "            sleeping = 0\n",
    "        t_final = time.time()\n",
    "        elapsed_time = t_final - t_blinks\n",
    "\n",
    "        # Update blink count per second and blink count per minute\n",
    "        if elapsed_time >= (temporary_count + 1):\n",
    "          temporary_count = elapsed_time\n",
    "          blinks_per_sec = blink_count - count_list[-1] if count_list else blink_count\n",
    "          count_list.append(blinks_per_sec)\n",
    "          count_list = count_list if (len(count_list) <= 60) else count_list[-60:]\n",
    "\n",
    "        blinks_per_min = 15 if elapsed_time <= 60 else sum(count_list)\n",
    "\n",
    "        # Display blink-related information on the frame\n",
    "        cv2.putText(frame, f\"Blinks: {blink_count}\", (1, 120),\n",
    "          cv2.FONT_HERSHEY_DUPLEX,\n",
    "          0.9, (109, 233, 219), 2)\n",
    "        \n",
    "        time_spent = (t_final - t_initial) if sleeping == 1 else 0.0\n",
    "        cv2.putText(frame, f\"Time: {round(time_spent, 3)}\", (1, 80),\n",
    "          cv2.FONT_HERSHEY_DUPLEX,\n",
    "          0.9, (255, 255, 255), 2)\n",
    "                \n",
    "        # Provide a warning if signs of sleepiness are detected\n",
    "        if blinks_per_min < 10 or time_spent >= 1.5:\n",
    "          cv2.rectangle(frame, (30, 400), (610, 452), (109, 233, 219), -1)\n",
    "          cv2.putText(frame, f\"You might be sleepy,\", (60, 420),\n",
    "          cv2.FONT_HERSHEY_DUPLEX, 0.85, (58, 58, 55), 1)\n",
    "          cv2.putText(frame, f\"consider taking a break.\", (180, 450),\n",
    "            cv2.FONT_HERSHEY_DUPLEX,\n",
    "            0.85, (58, 58, 55), 1)\n",
    "        \n",
    "      except:\n",
    "        pass\n",
    "\n",
    "      # Display the frame with annotations\n",
    "      cv2.imshow('Camera', frame)\n",
    "\n",
    "      # Break the loop if 'c' key is pressed\n",
    "      if cv2.waitKey(10) & 0xFF == ord('c'):\n",
    "        break\n",
    "\n",
    "# Release the camera and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate through the detected face landmarks in the FaceMesh output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for face_landmarks in facemesh_output.multi_face_landmarks:\n",
    "  # Extract the coordinates of all facial landmarks for the current face\n",
    "  face = face_landmarks\n",
    "    \n",
    "  # Enumerate through each facial landmark and print its identifier (id_coord)\n",
    "  # This provides the index of the landmark within the face.landmark list\n",
    "  for id_coord, coord_xyz in enumerate(face.landmark):\n",
    "    print(id_coord)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
